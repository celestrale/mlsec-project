{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo : Crafting ensemble adversarial attacks & testing their transferability\n",
    "### Machine Learning Security Project 2 - Jules COOPER, Leonie MAIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project instructions:**\n",
    "Consider 3 models from RobustBench (CIFAR10, L-inf) and craft universal (and untargeted) adversarial examples aimed to fool the 3 models at the same time. Evaluate transferability of such adversarial examples to other 7 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import secml\n",
    "    import foolbox\n",
    "except ImportError:\n",
    "    %pip install git+https://github.com/pralab/secml\n",
    "    %pip install foolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models from RobustBench (Linf, CIFAR-10) tested were:\n",
    "\n",
    "| Model name | Model ID | Clean Accuracy  | Robust Accuracy  |  Architecture  |\n",
    "|----|----|----|----|---|\n",
    "| secml_model1 | Ding2020MMA | 84.36% | 41.44% | WideResNet-28-4 |\n",
    "| secml_model2 | Wong2020Fast | 83.34% | 43.21% | PreActResNet-18 |\n",
    "| secml_model3 | Andriushchenko2020Understanding | 79.84% | 43.93% | PreActResNet-18 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secml.data.loader.c_dataloader_cifar import CDataLoaderCIFAR10\n",
    "from secml.ml.classifiers import CClassifierPyTorch\n",
    "from secml.ml.features.normalization import CNormalizerMinMax\n",
    "\n",
    "\n",
    "train_ds, test_ds = CDataLoaderCIFAR10().load()\n",
    "dataset_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "normalizer = CNormalizerMinMax().fit(train_ds.X)\n",
    "\n",
    "from robustbench.utils import load_model\n",
    "\n",
    "model1 = load_model(model_name='Ding2020MMA', dataset='cifar10', threat_model='Linf')\n",
    "secml_model1 = CClassifierPyTorch(model1, input_shape=(3,32,32), pretrained=True)\n",
    "model2 = load_model(model_name='Wong2020Fast', dataset='cifar10', threat_model='Linf')\n",
    "secml_model2 = CClassifierPyTorch(model2, input_shape=(3,32,32), pretrained=True)\n",
    "model3 = load_model(model_name='Andriushchenko2020Understanding', dataset='cifar10', threat_model='Linf')\n",
    "secml_model3 = CClassifierPyTorch(model3, input_shape=(3,32,32), pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secml.ml.classifiers.loss import CLossCrossEntropy\n",
    "from secml.array import CArray\n",
    "\n",
    "\n",
    "def pgd_linf_mult_untargeted(x, y, models, eps, alpha, steps):\n",
    "    \"\"\"Performs a Projected Gradient Descent attack on one or more models by averaging their gradient at\"\"\"\n",
    "\n",
    "    # we need the gradient of the softmax\n",
    "    for clf in models :\n",
    "            clf.softmax_outputs = True\n",
    "    \n",
    "    # Using cross entropy as loss function\n",
    "    loss_func = CLossCrossEntropy()\n",
    "    x_adv = x.deepcopy()  \n",
    "\n",
    "    for i in range(steps):\n",
    "        gradients = []\n",
    "        # Follow progression of attack\n",
    "        if i % 10 == 0 : \n",
    "                print((i/steps)*100,\"%\")\n",
    "\n",
    "        # Calculate scores and gradients of each model        \n",
    "        for clf_index in range(len(models)):\n",
    "                                       \n",
    "            scores = models[clf_index].decision_function(x_adv)\n",
    "\n",
    "            # gradient of the loss considering the output logits\n",
    "            loss_gradient = loss_func.dloss(y_true=y, score=scores)\n",
    "            # gradient of the output logits considering the input\n",
    "            clf_gradient = models[clf_index].grad_f_x(x_adv, y)\n",
    "\n",
    "            # gradient of the loss function considering the input\n",
    "            gradient = clf_gradient * loss_gradient\n",
    "\n",
    "            gradients.append(gradient)\n",
    "\n",
    "\n",
    "        gradient = gradients[0]\n",
    "\n",
    "        # If multiple models, calculate the mean gradient\n",
    "        if (len(gradients) > 1):\n",
    "            gradient = CArray([arr.tondarray() for arr in gradients])\n",
    "            gradient = gradient.mean(axis=0)\n",
    "\n",
    "        # Normalize mean gradient\n",
    "        gradient = gradient.sign()\n",
    "\n",
    "        # make step\n",
    "        x_adv = x_adv + alpha * gradient\n",
    "\n",
    "        # project inside epsilon-ball : For Linf, only need to keep it between epsilon boundaries\n",
    "        delta = (x_adv - x).clip(-eps,eps)\n",
    "        x_adv = x + delta\n",
    "\n",
    "        # force input bounds\n",
    "        x_adv = x_adv.clip(0, 1)\n",
    "\n",
    "    predict = []\n",
    "    \n",
    "\n",
    "    for clf in models:\n",
    "        #Restore outputs\n",
    "        clf.softmax_outputs = False\n",
    "        # Add prediction of each classifier\n",
    "        predict.append(clf.predict(x_adv))\n",
    "\n",
    "    return x_adv, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def multiple_runs(max_iterations, models, eps, alpha, steps):\n",
    "    \"\"\"Returns first successful attack\"\"\"\n",
    "\n",
    "    adversarial = False\n",
    "    n = 0\n",
    "    while n < max_iterations and not adversarial :\n",
    "        # Choosing a random image from the test set\n",
    "        i = random.randint(0,10000)\n",
    "        pt = test_ds[i, :]\n",
    "        x0, y0 = pt.X, pt.Y\n",
    "\n",
    "        # Normalizing the input\n",
    "        x0 = normalizer.transform(x0)\n",
    "\n",
    "        print(f\"attack_number {n} on image {i}\")\n",
    "        print(f\"Starting point has label: {dataset_labels[y0.item()]}\")\n",
    "\n",
    "        # Run one (combined) attack \n",
    "        x_adv, y_advs = pgd_linf_mult_untargeted(x0, y0, models, eps, alpha, steps)\n",
    "        \n",
    "        adversarial = True\n",
    "        for y_adv in y_advs:\n",
    "            print(f\"Adversarial point has label: {dataset_labels[y_adv.item()]}\")\n",
    "            # If at least one model still predicts real label after attack, unsuccessful attack\n",
    "            if y_adv.item() == y0.item():\n",
    "                adversarial = False\n",
    "    return x_adv, i\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High number of steps to try for best accuracy\n",
    "steps = 100\n",
    "# Standard Linf budget\n",
    "eps = 8/255\n",
    "alpha = eps/2\n",
    "\n",
    "# Running on more robust models\n",
    "x_adv, image_index = multiple_runs(20,[secml_model1, secml_model2, secml_model3],eps,alpha,steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading every models to the variable test_models\n",
    "transfer_models_name = [\"Amini2024MeanSparse_Ra_WRN_70_16\", \"Gowal2021Improving_70_16_ddpm_100m\", \"Cui2023Decoupled_WRN-28-10\", \"Wang2023Better_WRN-28-10\", \"Rebuffi2021Fixing_106_16_cutmix_ddpm\", \"Huang2022Revisiting_WRN-A4\", \"Kang2021Stable\"]\n",
    "test_models = []\n",
    "for model_name_t in transfer_models_name:\n",
    "\n",
    "    model = load_model(model_name=model_name_t, dataset='cifar10', threat_model='Linf')\n",
    "    secml_model = CClassifierPyTorch(model, input_shape=(3,32,32), pretrained=True)\n",
    "    test_models.append(secml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = test_ds[image_index, :]\n",
    "x0, y0 = pt.X, pt.Y\n",
    "success_models=[]\n",
    "total_local_models=[]\n",
    "total_run = 0\n",
    "number_success = 0\n",
    "\n",
    "for i in range(len(test_models)):\n",
    "    success_models.append(0)\n",
    "    total_local_models.append(0)\n",
    "\n",
    "# run the prediction with the adversarial example\n",
    "for i in range(len(test_models)):\n",
    "    \n",
    "    y_pred = test_models[i].predict(x_adv)\n",
    "    if (y_pred.item() != y0.item()):\n",
    "        number_success+=1\n",
    "        success_models[i]+=1\n",
    "\n",
    "    total_local_models[i]+=1\n",
    "    total_run +=1\n",
    "\n",
    "print(f\"{total_local_models[0]} attacks were transfered other {len(test_models)} models\")\n",
    "print(f\"Within the {total_run} attacks, {number_success} succeeded: accuracy {number_success/total_run*100}%\")\n",
    "print(\"Individual model statistics\")\n",
    "\n",
    "\n",
    "for i in range(len(test_models)):\n",
    "    if (success_models[i]):\n",
    "        print(f\"\\t transferability attack successful on model {i}\")\n",
    "    else:\n",
    "        print(f\"\\t transferability attack unsuccessful on model {i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
